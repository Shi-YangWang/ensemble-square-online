{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Ensemble^2$(MOD)\n",
    "尝试视频异常检测的思路：\n",
    "- 提取特征\n",
    "- 集成学习\n",
    "- 挖掘时间依赖性\n",
    "\n",
    "在提取特征这一步，接着集成：\n",
    "- 基于预测误差\n",
    "- 基于统计特征\n",
    "\n",
    "算法因此得名."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成特征矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探索批处理算法可行性\n",
    "df_train = pd.read_csv('data/22th_ts_train.csv')\n",
    "series = df_train['value']\n",
    "# 1. ARIMA\n",
    "from statsmodels.tsa.ar_model import ar_select_order\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "mod = ar_select_order(series, maxlag=30)\n",
    "res = AutoReg(series, lags = mod.ar_lags).fit()\n",
    "df_train['arima'] = kde_threshold(res.resid)\n",
    "# 2. STL\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "result=seasonal_decompose(series, model='additive', period=1440)\n",
    "result.resid.fillna(method='ffill', inplace=True)\n",
    "result.resid.fillna(method='bfill', inplace=True)\n",
    "df_train['stl'] = kde_threshold(result.resid)\n",
    "# 3. SVR\n",
    "svr = OnlineSVR(series[0:4*1440])\n",
    "Xhat = []\n",
    "for i in tqdm(range(0, series.size)):\n",
    "    xhat = svr.update(series[i])\n",
    "    Xhat.append(xhat)\n",
    "df_train['svr'] = kde_threshold(pd.Series(Xhat) - series)\n",
    "# 4. Diff\n",
    "df_train['diff'] = kde_threshold(series.diff().fillna(0))\n",
    "# 5. Z Score\n",
    "mean = series.mean()\n",
    "std = series.std()\n",
    "df_train['z-score'] = kde_threshold((series - mean) / std)\n",
    "# 6. Matrix Profile\n",
    "'''\n",
    "    窗口大小不同，MP计算结果完全不同\n",
    "    暂将窗口大小设置为1天\n",
    "'''\n",
    "import matrixprofile as mp\n",
    "profile= mp.compute(series.values, windows=1440, n_jobs=8)\n",
    "df_train['mp'] = kde_threshold(pd.Series(np.concatenate((np.zeros(16), profile['mp']), axis=0)))\n",
    "# 7. Permutation Entropy\n",
    "'''\n",
    "    取相反数\n",
    "    时间序列变得有序的情况：连续0值\n",
    "'''\n",
    "from pyentrp import entropy as ent\n",
    "perm_ent_series = []\n",
    "for i in range(0, series.count()-30):\n",
    "    perm_ent_series.append(-ent.permutation_entropy(series[i: i+30], order=3))\n",
    "df_train['entropy'] = kde_threshold(pd.Series(np.concatenate((np.zeros(30), perm_ent_series), axis=0)))\n",
    "# 8. DFT\n",
    "transformed = np.fft.fft(series)\n",
    "df_train['fft'] = kde_threshold(pd.Series(np.real(transformed)))\n",
    "# 9. Holt-Winters\n",
    "for alpha in [0.2, 0.4, 0.6, 0.8]:\n",
    "    for beta in [0.2, 0.4, 0.6, 0.8]:\n",
    "        for gamma in [0.2, 0.4, 0.6, 0.8]:\n",
    "            df_train[\"holt-winters_{}_{}_{}\".format(alpha, beta, gamma)] = kde_threshold(pd.Series(holt_winters(series,alpha=alpha, beta=beta, gamma=gamma)-series))\n",
    "# 10. EWMA\n",
    "for alpha in [0.2, 0.4, 0.6, 0.8]:\n",
    "    df_train[\"ewma_{}\".format(alpha)] = kde_threshold(pd.Series(ewma(series,alpha=alpha)-series))\n",
    "df_train.fillna(0, inplace=True)\n",
    "# 保存中间结果（二元特征值表）\n",
    "df_train.to_csv('22th_train_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用梯度提升树集成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature = pd.read_csv('22th_train_table.csv')\n",
    "features = df_feature.drop(['timestamp', 'value', 'label'], axis=1)\n",
    "labels   = df_feature['label']\n",
    "testparams = {\n",
    " \n",
    "    \"objective\":\"binary:logistic\",\n",
    "    \"biister\":\"gbtree\",\n",
    "    \"eta\":\"0.1\",\n",
    "    \"eval_metric\":\"auc\",\n",
    "    # \"scale_pos_weight\":neg_num/pos_num,\n",
    "    \"max_depth\":6\n",
    " \n",
    "}\n",
    "num_round = 50\n",
    "xgb_train = xgb.DMatrix(features, labels)\n",
    "xgb_test  = xgb.DMatrix(features, labels)\n",
    "watchlist = [(xgb_train, 'train'), (xgb_test, 'test')]\n",
    "model = xgb.train(testparams, xgb_train, num_round, watchlist)\n",
    "# 保存模型\n",
    "xgb.save(model, '22th_train.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "def kde_threshold(series):\n",
    "    theta=0.01\n",
    "    bandwidth=1\n",
    "    kernel='epanechnikov'\n",
    "    model = KernelDensity(bandwidth=bandwidth, kernel=kernel)\n",
    "    model.fit(series[:, np.newaxis])\n",
    "    x_range = np.linspace(series.min() - 1, series.max() + 1, 500)\n",
    "    x_log_prob = model.score_samples(x_range[:, np.newaxis])\n",
    "    x_prob = np.exp(x_log_prob)\n",
    "    nx_prob = x_prob / x_prob.sum()\n",
    "    idx = pd.Series(nx_prob.cumsum() - (1-theta)).abs().argmin()\n",
    "    return series.apply(lambda x: 1 if abs(x) > abs(x_range[idx]) else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnlineARIMA:\n",
    "    '''\n",
    "        Initialization\n",
    "        @param series: 1D train data\n",
    "    '''\n",
    "    def __init__(self, series, maxlag=30, lrate=1.75, epsilon=10**(-0.5)):\n",
    "        self.maxlag = maxlag\n",
    "        self.lrate = lrate\n",
    "        mod = ar_select_order(series, maxlag=maxlag)\n",
    "        self.mask = mod.ar_lags\n",
    "        res = AutoReg(series, lags = mod.ar_lags).fit()\n",
    "        self.w = res.params[1:]\n",
    "        self.window = series[-maxlag:].values.tolist()\n",
    "        self.A_inv = np.eye(len(self.mask)) * epsilon\n",
    "    \n",
    "    '''\n",
    "        Update\n",
    "    '''\n",
    "    def update(self, x):\n",
    "        arr = self.window.copy()\n",
    "        arr.append(0)\n",
    "        arr = arr[::-1]\n",
    "        mask = self.mask\n",
    "        masked = np.array(arr)[mask]\n",
    "        xhat = np.dot(masked, self.w)\n",
    "        diff = xhat - x\n",
    "        grad = 2 * diff * masked.reshape(1, -1)\n",
    "        self.A_inv = self.A_inv - self.A_inv @ grad.T * grad * self.A_inv / (1 + grad * self.A_inv * grad.T)\n",
    "        self.w = self.w - self.lrate * (grad * self.A_inv)[0]\n",
    "        def update_array(array, update):\n",
    "            updated = np.roll(array, -1)\n",
    "            updated[-1] = update\n",
    "            return updated\n",
    "        self.window = update_array(self.window, x).tolist()\n",
    "        return xhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online STL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnlineSTL:\n",
    "    '''\n",
    "        df_train: 1D Series, shape=(1,4*m)\n",
    "        m       ：period\n",
    "    '''\n",
    "    def __init__(self, df_train, m):\n",
    "        self.m = m\n",
    "        # Initialize\n",
    "        # A.shape=(1, 4m)\n",
    "        self.A = np.array(df_train).copy()\n",
    "        result=seasonal_decompose(self.A, model='additive', period=m)\n",
    "        self.K = np.array(result.seasonal).copy()\n",
    "        self.S = np.array(self.K[-m:]).copy()\n",
    "        self.T = np.array(self.K[-m:]).copy()\n",
    "        self.D = np.array((df_train - result.seasonal)[-m:]).copy()\n",
    "        self.i = 4 * m\n",
    "\n",
    "        self.asym_filter_4m = self.async_filter(4*m)\n",
    "        self.asym_filter_m  = self.async_filter(m)\n",
    "    \n",
    "    '''\n",
    "        Tri cube kernel filter\n",
    "    '''\n",
    "    def tri_cube(self, u):\n",
    "        if 0 <= u < 1:\n",
    "            return ( 1 - u ** 3 ) ** 3\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def async_filter(self, n):\n",
    "        asym_filter_n = np.zeros((n))\n",
    "        for j in range(0, n):\n",
    "            asym_filter_n[-j-1] = self.tri_cube(j / n)\n",
    "        return asym_filter_n\n",
    "\n",
    "    '''\n",
    "        Xi: Recent data point\n",
    "        i : sequential index\n",
    "    '''\n",
    "    def update(self, Xi):\n",
    "        # Update\n",
    "        def update_array(array, update):\n",
    "            updated = np.roll(array, -1)\n",
    "            updated[-1] = update\n",
    "            return updated\n",
    "        update_array(self.A, Xi)\n",
    "        b = Xi\n",
    "        def apply_trend_filter(filter, signal):\n",
    "            return np.dot(filter, signal) / np.linalg.norm(x=filter, ord=1)\n",
    "        t1= apply_trend_filter(self.asym_filter_4m, self.A)\n",
    "        d1=b - t1\n",
    "        self.i = self.i + 1\n",
    "        r = (self.i-1) % self.m\n",
    "        gamma = 0.7\n",
    "        self.S[r] = gamma * d1 + (1-gamma) * self.S[r]\n",
    "        update_array(self.K, self.S[r])\n",
    "        t4= apply_trend_filter(self.asym_filter_4m, self.K)\n",
    "        d5= b - t1 - t4\n",
    "        self.T[r] = gamma * d5 + (1-gamma) * self.T[r]\n",
    "        b = b - self.T[r]\n",
    "        update_array(self.D, b)\n",
    "        Ti=apply_trend_filter(self.asym_filter_m, self.D)\n",
    "        Si=self.T[r]\n",
    "        Ri=Xi - Ti - Si\n",
    "        return Ti, Si, Ri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "class OnlineSVR:\n",
    "    '''\n",
    "        Initialize\n",
    "    '''\n",
    "    def __init__(self, series, num_features=30):\n",
    "        self.svr = OSVR(numFeatures = num_features, C = 2, eps = 0.01, kernelParam = 1, bias = 0, debug = False)\n",
    "        self.window = series[-num_features:]\n",
    "        for i in tqdm(range(0, min(series.size, 1 * 1440) - num_features)):\n",
    "            # slow, so use sampling here.\n",
    "            if (i % 10 == 0):\n",
    "                self.svr.learn(series[i:i+num_features], series[i+num_features])\n",
    "    \n",
    "    '''\n",
    "        Update\n",
    "    '''\n",
    "    def update(self, x):\n",
    "        xhat = self.svr.predict(self.window)\n",
    "        def update_array(array, update):\n",
    "            updated = np.roll(array, -1)\n",
    "            updated[-1] = update\n",
    "            return updated\n",
    "        self.window = update_array(self.window, x).tolist()\n",
    "        return x - xhat[0,0]\n",
    "def sign(x):\n",
    "    \"\"\" Returns sign. Numpys sign function returns 0 instead of 1 for zero values. :( \"\"\"\n",
    "    if x >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "class OSVR:\n",
    "    def __init__(self, numFeatures, C, eps, kernelParam, bias = 0, debug = False):\n",
    "        # Configurable Parameters\n",
    "        self.numFeatures = numFeatures\n",
    "        self.C = C\n",
    "        self.eps = eps\n",
    "        self.kernelParam = kernelParam\n",
    "        self.bias = bias\n",
    "        self.debug = debug\n",
    "        \n",
    "        if self.debug:\n",
    "            print('SELF',self.C,self.eps,self.kernelParam)\n",
    "        # Algorithm initialization\n",
    "        self.numSamplesTrained = 0\n",
    "        self.weights = np.array([])\n",
    "        \n",
    "        # Samples X (features) and Y (truths)\n",
    "        self.X = list()\n",
    "        self.Y = list()\n",
    "        # Working sets, contains indices pertaining to X and Y\n",
    "        self.supportSetIndices = list()\n",
    "        self.errorSetIndices = list()\n",
    "        self.remainderSetIndices = list()\n",
    "        self.R = np.matrix([])\n",
    "\n",
    "    def findMinVariation(self, H, beta, gamma, i):\n",
    "        \"\"\" Finds the variations of each sample to the new set.\n",
    "        Lc1: distance of the new sample to the SupportSet\n",
    "        Lc2: distance of the new sample to the ErrorSet\n",
    "        Ls(i): distance of the support samples to the ErrorSet/RemainingSet\n",
    "        Le(i): distance of the error samples to the SupportSet\n",
    "        Lr(i): distance of the remaining samples to the SupportSet\n",
    "        \"\"\"\n",
    "        # Find direction q of the new sample\n",
    "        q = -sign(H[i])\n",
    "        # Compute variations\n",
    "        Lc1 = self.findVarLc1(H, gamma, q, i)\n",
    "        q = sign(Lc1)\n",
    "        Lc2 = self.findVarLc2(H, q, i)\n",
    "        Ls = self.findVarLs(H, beta, q)\n",
    "        Le = self.findVarLe(H, gamma, q)\n",
    "        Lr = self.findVarLr(H, gamma, q)\n",
    "        # Check for duplicate minimum values, grab one with max gamma/beta, set others to inf\n",
    "        # Support set\n",
    "        if Ls.size > 1:\n",
    "            minS = np.abs(Ls).min()\n",
    "            results = np.array([k for k,val in enumerate(Ls) if np.abs(val)==minS])\n",
    "            if len(results) > 1:\n",
    "                betaIndex = beta[results+1].argmax()\n",
    "                Ls[results] = q*np.inf\n",
    "                Ls[results[betaIndex]] = q*minS\n",
    "        # Error set\n",
    "        if Le.size > 1:\n",
    "            minE = np.abs(Le).min()\n",
    "            results = np.array([k for k,val in enumerate(Le) if np.abs(val)==minE])\n",
    "            if len(results) > 1:\n",
    "                errorGamma = gamma[self.errorSetIndices]\n",
    "                gammaIndex = errorGamma[results].argmax()\n",
    "                Le[results] = q*np.inf\n",
    "                Le[results[gammaIndex]] = q*minE\n",
    "        # Remainder Set\n",
    "        if Lr.size > 1:\n",
    "            minR = np.abs(Lr).min()\n",
    "            results = np.array([k for k,val in enumerate(Lr) if np.abs(val)==minR])\n",
    "            if len(results) > 1:\n",
    "                remGamma = gamma[self.remainderSetIndices]\n",
    "                gammaIndex = remGamma[results].argmax()\n",
    "                Lr[results] = q*np.inf\n",
    "                Lr[results[gammaIndex]] = q*minR\n",
    "        \n",
    "        # Find minimum absolute variation of all, retain signs. Flag determines set-switching cases.\n",
    "        minLsIndex = np.abs(Ls).argmin()\n",
    "        minLeIndex = np.abs(Le).argmin()\n",
    "        minLrIndex = np.abs(Lr).argmin()\n",
    "        minIndices = [None, None, minLsIndex, minLeIndex, minLrIndex]\n",
    "        minValues = np.array([Lc1, Lc2, Ls[minLsIndex], Le[minLeIndex], Lr[minLrIndex]])\n",
    "\n",
    "        if np.abs(minValues).min() == np.inf:\n",
    "            if self.debug:\n",
    "                print('No weights to modify! Something is wrong.')\n",
    "            sys.exit()\n",
    "        flag = np.abs(minValues).argmin()\n",
    "        if self.debug:\n",
    "            print('MinValues',minValues)\n",
    "        return minValues[flag], flag, minIndices[flag]\n",
    "\n",
    "    def findVarLc1(self, H, gamma, q, i):\n",
    "        # weird hacks below\n",
    "        Lc1 = np.nan\n",
    "        if gamma.size < 2:\n",
    "            g = gamma\n",
    "        else:\n",
    "            g = gamma.item(i)\n",
    "        # weird hacks above\n",
    "\n",
    "        if  g <= 0:\n",
    "            Lc1 = np.array(q*np.inf)\n",
    "        elif H[i] > self.eps and -self.C < self.weights[i] and self.weights[i] <= 0:\n",
    "            Lc1 = (-H[i] + self.eps) / g\n",
    "        elif H[i] < -self.eps and 0 <= self.weights[i] and self.weights[i] <= self.C:\n",
    "            Lc1 = (-H[i] - self.eps) / g\n",
    "        elif self.debug:\n",
    "            print('Something is weird.')\n",
    "            print('i',i)\n",
    "            print('q',q)\n",
    "            print('gamma',gamma)\n",
    "            print('g',g)\n",
    "            print('H[i]',H[i])\n",
    "            print('weights[i]',self.weights[i])\n",
    "        \n",
    "        if np.isnan(Lc1):\n",
    "            Lc1 = np.array(q*np.inf)\n",
    "        return Lc1.item()\n",
    "\n",
    "    def findVarLc2(self, H, q, i):\n",
    "        if len(self.supportSetIndices) > 0:\n",
    "            if q > 0:\n",
    "                Lc2 = -self.weights[i] + self.C\n",
    "            else:\n",
    "                Lc2 = -self.weights[i] - self.C\n",
    "        else:\n",
    "            Lc2 = np.array(q*np.inf)\n",
    "        if np.isnan(Lc2):\n",
    "            Lc2 = np.array(q*np.inf)\n",
    "        return Lc2\n",
    "\n",
    "    def findVarLs(self, H, beta, q):\n",
    "        if len(self.supportSetIndices) > 0 and len(beta) > 0:\n",
    "            Ls = np.zeros([len(self.supportSetIndices),1])\n",
    "            supportWeights = self.weights[self.supportSetIndices]\n",
    "            supportH = H[self.supportSetIndices]\n",
    "            for k in range(len(self.supportSetIndices)):\n",
    "                if q*beta[k+1] == 0:\n",
    "                    Ls[k] = q*np.inf\n",
    "                elif q*beta[k+1] > 0:\n",
    "                    if supportH[k] > 0:\n",
    "                        if supportWeights[k] < -self.C:\n",
    "                            Ls[k] = (-supportWeights[k] - self.C) / beta[k+1]\n",
    "                        elif supportWeights[k] <= 0:\n",
    "                            Ls[k] = -supportWeights[k] / beta[k+1]\n",
    "                        else:\n",
    "                            Ls[k] = q*np.inf\n",
    "                    else:\n",
    "                        if supportWeights[k] < 0:\n",
    "                            Ls[k] = -supportWeights[k] / beta[k+1]\n",
    "                        elif supportWeights[k] <= self.C:\n",
    "                            Ls[k] = (-supportWeights[k] + self.C) / beta[k+1]\n",
    "                        else:\n",
    "                            Ls[k] = q*np.inf\n",
    "                else:\n",
    "                    if supportH[k] > 0:\n",
    "                        if supportWeights[k] > 0:\n",
    "                            Ls[k] = -supportWeights[k] / beta[k+1]\n",
    "                        elif supportWeights[k] >= -self.C:\n",
    "                            Ls[k] = (-supportWeights[k] - self.C) / beta[k+1]\n",
    "                        else:\n",
    "                            Ls[k] = q*np.inf\n",
    "                    else:\n",
    "                        if supportWeights[k] > self.C:\n",
    "                            Ls[k] = (-supportWeights[k] + self.C) / beta[k+1]\n",
    "                        elif supportWeights[k] >= self.C:\n",
    "                            Ls[k] = -supportWeights[k] / beta[k+1]\n",
    "                        else:\n",
    "                            Ls[k] = q*np.inf\n",
    "        else:\n",
    "            Ls = np.array([q*np.inf])\n",
    "\n",
    "        # Correct for NaN\n",
    "        Ls[np.isnan(Ls)] = q*np.inf\n",
    "        if Ls.size > 1:\n",
    "            Ls.shape = (len(Ls),1)\n",
    "            # Check for broken signs\n",
    "            for val in Ls:\n",
    "                if sign(val) == -sign(q) and val != 0:\n",
    "                    if self.debug:\n",
    "                        print('Sign mismatch error in Ls! Exiting.')\n",
    "                    sys.exit()\n",
    "        # print('findVarLs',Ls)\n",
    "        return Ls\n",
    "        \n",
    "    def findVarLe(self, H, gamma, q):\n",
    "        if len(self.errorSetIndices) > 0:\n",
    "            Le = np.zeros([len(self.errorSetIndices),1])\n",
    "            errorGamma = gamma[self.errorSetIndices]\n",
    "            errorWeights = self.weights[self.errorSetIndices]\n",
    "            errorH = H[self.errorSetIndices]\n",
    "            for k in range(len(self.errorSetIndices)):\n",
    "                if q*errorGamma[k] == 0:\n",
    "                    Le[k] = q*np.inf\n",
    "                elif q*errorGamma[k] > 0:\n",
    "                    if errorWeights[k] > 0:\n",
    "                        if errorH[k] < -self.eps:\n",
    "                            Le[k] = (-errorH[k] - self.eps) / errorGamma[k]\n",
    "                        else:\n",
    "                            Le[k] = q*np.inf\n",
    "                    else:\n",
    "                        if errorH[k] < self.eps:\n",
    "                            Le[k] = (-errorH[k] + self.eps) / errorGamma[k]\n",
    "                        else:\n",
    "                            Le[k] = q*np.inf\n",
    "                else:\n",
    "                    if errorWeights[k] > 0:\n",
    "                        if errorH[k] > -self.eps:\n",
    "                            Le[k] = (-errorH[k] - self.eps) / errorGamma[k]\n",
    "                        else:\n",
    "                            Le[k] = q*np.inf\n",
    "                    else:\n",
    "                        if errorH[k] > self.eps:\n",
    "                            Le[k] = (-errorH[k] + self.eps) / errorGamma[k]\n",
    "                        else:\n",
    "                            Le[k] = q*np.inf\n",
    "        else:\n",
    "            Le = np.array([q*np.inf])\n",
    "\n",
    "        # Correct for NaN\n",
    "        Le[np.isnan(Le)] = q*np.inf\n",
    "        if Le.size > 1:\n",
    "            Le.shape = (len(Le),1)\n",
    "            # Check for broken signs\n",
    "            for val in Le:\n",
    "                if sign(val) == -sign(q) and val != 0:\n",
    "                    if self.debug:\n",
    "                        print('Sign mismatch error in Le! Exiting.')\n",
    "                    sys.exit()\n",
    "        # print('findVarLe',Le)\n",
    "        return Le\n",
    "\n",
    "    def findVarLr(self, H, gamma, q):\n",
    "        if len(self.remainderSetIndices) > 0:\n",
    "            Lr = np.zeros([len(self.remainderSetIndices),1])\n",
    "            remGamma = gamma[self.remainderSetIndices]\n",
    "            remH = H[self.remainderSetIndices]\n",
    "            for k in range(len(self.remainderSetIndices)):\n",
    "                if q*remGamma[k] == 0:\n",
    "                    Lr[k] = q*np.inf\n",
    "                elif q*remGamma[k] > 0:\n",
    "                    if remH[k] < -self.eps:\n",
    "                        Lr[k] = (-remH[k] - self.eps) / remGamma[k]\n",
    "                    elif remH[k] < self.eps:\n",
    "                        Lr[k] = (-remH[k] + self.eps) / remGamma[k]\n",
    "                    else:\n",
    "                        Lr[k] = q*np.inf\n",
    "                else:\n",
    "                    if remH[k] > self.eps:\n",
    "                        Lr[k] = (-remH[k] + self.eps) / remGamma[k]\n",
    "                    elif remH[k] > -self.eps:\n",
    "                        Lr[k] = (-remH[k] - self.eps) / remGamma[k]\n",
    "                    else:\n",
    "                        Lr[k] = q*np.inf\n",
    "        else:\n",
    "            Lr = np.array([q*np.inf])\n",
    "\n",
    "        # Correct for NaN\n",
    "        Lr[np.isnan(Lr)] = q*np.inf\n",
    "        if Lr.size > 1:\n",
    "            Lr.shape = (len(Lr),1)\n",
    "            # Check for broken signs\n",
    "            for val in Lr:\n",
    "                if sign(val) == -sign(q) and val != 0:\n",
    "                    if self.debug:\n",
    "                        print('Sign mismatch error in Lr! Exiting.')\n",
    "                    sys.exit()\n",
    "        # print('findVarLr',Lr)\n",
    "        return Lr\n",
    "\n",
    "    def computeKernelOutput(self, set1, set2):\n",
    "        \"\"\"Compute kernel output. Uses a radial basis function kernel.\"\"\"\n",
    "        X1 = np.matrix(set1)\n",
    "        X2 = np.matrix(set2).T\n",
    "        # Euclidean distance calculation done properly\n",
    "        [S,R] = X1.shape\n",
    "        [R2,Q] = X2.shape\n",
    "        X = np.zeros([S,Q])\n",
    "        if Q < S:\n",
    "            copies = np.zeros(S,dtype=int)\n",
    "            for q in range(Q):\n",
    "                if self.debug:\n",
    "                    print('X1',X1)\n",
    "                    print('X2copies',X2.T[q+copies,:])\n",
    "                    print('power',np.power(X1-X2.T[q+copies,:],2))\n",
    "                xsum = np.sum(np.power(X1-X2.T[q+copies,:],2),axis=1)\n",
    "                xsum.shape = (xsum.size,)\n",
    "                X[:,q] = xsum\n",
    "        else:\n",
    "            copies = np.zeros(Q,dtype=int)\n",
    "            for i in range(S):\n",
    "                X[i,:] = np.sum(np.power(X1.T[:,i+copies]-X2,2),axis=0)\n",
    "        X = np.sqrt(X)\n",
    "        y = np.matrix(np.exp(-self.kernelParam*X**2))\n",
    "        if self.debug:\n",
    "            print('distance',X)\n",
    "            print('kernelOutput',y)\n",
    "        return y\n",
    "    \n",
    "    def predict(self, newSampleX):\n",
    "        X = np.array(self.X)\n",
    "        newX = np.array(newSampleX)\n",
    "        weights = np.array(self.weights)\n",
    "        weights.shape = (weights.size,1)\n",
    "        if self.numSamplesTrained > 0:\n",
    "            y = self.computeKernelOutput(X, newX)\n",
    "            return (weights.T @ y).T + self.bias\n",
    "        else:\n",
    "            return np.zeros_like(newX) + self.bias\n",
    "\n",
    "    def computeMargin(self, newSampleX, newSampleY):\n",
    "        fx = self.predict(newSampleX)\n",
    "        newSampleY = np.array(newSampleY)\n",
    "        newSampleY.shape = (newSampleY.size, 1)\n",
    "        if self.debug:\n",
    "            print('fx',fx)\n",
    "            print('newSampleY',newSampleY)\n",
    "            print('hx',fx-newSampleY)\n",
    "        return fx-newSampleY\n",
    "\n",
    "    def computeBetaGamma(self,i):\n",
    "        \"\"\"Returns beta and gamma arrays.\"\"\"\n",
    "        # Compute beta vector\n",
    "        X = np.array(self.X)\n",
    "        Qsi = self.computeQ(X[self.supportSetIndices,:], X[i,:])\n",
    "        if len(self.supportSetIndices) == 0 or self.R.size == 0:\n",
    "            beta = np.array([])\n",
    "        else:\n",
    "            beta = -self.R @ np.append(np.matrix([1]),Qsi,axis=0)\n",
    "        # Compute gamma vector\n",
    "        Qxi = self.computeQ(X, X[i,:])\n",
    "        Qxs = self.computeQ(X, X[self.supportSetIndices,:])\n",
    "        if len(self.supportSetIndices) == 0 or Qxi.size == 0 or Qxs.size == 0 or beta.size == 0:\n",
    "            gamma = np.array(np.ones_like(Qxi))\n",
    "        else:\n",
    "            gamma = Qxi + np.append(np.ones([self.numSamplesTrained,1]), Qxs, 1) @ beta\n",
    "\n",
    "        # Correct for NaN\n",
    "        beta[np.isnan(beta)] = 0\n",
    "        gamma[np.isnan(gamma)] = 0\n",
    "        if self.debug:\n",
    "            print('R',self.R)\n",
    "            print('beta',beta)\n",
    "            print('gamma',gamma)\n",
    "        return beta, gamma\n",
    "\n",
    "    def computeQ(self, set1, set2):\n",
    "        set1 = np.matrix(set1)\n",
    "        set2 = np.matrix(set2)\n",
    "        Q = np.matrix(np.zeros([set1.shape[0],set2.shape[0]]))\n",
    "        for i in range(set1.shape[0]):\n",
    "            for j in range(set2.shape[0]):\n",
    "                Q[i,j] = self.computeKernelOutput(set1[i,:],set2[j,:])\n",
    "        return np.matrix(Q)\n",
    "        \n",
    "    def adjustSets(self, H, beta, gamma, i, flag, minIndex):\n",
    "        if self.debug:\n",
    "            print('Entered adjustSet logic with flag {0} and minIndex {1}.'.format(flag,minIndex))\n",
    "        if flag not in range(5):\n",
    "            if self.debug:\n",
    "                print('Received unexpected flag {0}, exiting.'.format(flag))\n",
    "            sys.exit()\n",
    "        # add new sample to Support set\n",
    "        if flag == 0:\n",
    "            if self.debug:\n",
    "                print('Adding new sample {0} to support set.'.format(i))\n",
    "            H[i] = np.sign(H[i])*self.eps\n",
    "            self.supportSetIndices.append(i)\n",
    "            self.R = self.addSampleToR(i,'SupportSet',beta,gamma)\n",
    "            return H,True\n",
    "        # add new sample to Error set\n",
    "        elif flag == 1:\n",
    "            if self.debug: \n",
    "                print('Adding new sample {0} to error set.'.format(i))\n",
    "            self.weights[i] = np.sign(self.weights[i])*self.C\n",
    "            self.errorSetIndices.append(i)\n",
    "            return H,True\n",
    "        # move sample from Support set to Error or Remainder set\n",
    "        elif flag == 2: \n",
    "            index = self.supportSetIndices[minIndex]\n",
    "            weightsValue = self.weights[index]\n",
    "            if np.abs(weightsValue) < np.abs(self.C - abs(weightsValue)):\n",
    "                self.weights[index] = 0\n",
    "                weightsValue = 0\n",
    "            else:\n",
    "                self.weights[index] = np.sign(weightsValue)*self.C\n",
    "                weightsValue = self.weights[index]\n",
    "            # Move from support to remainder set\n",
    "            if weightsValue == 0:\n",
    "                if self.debug:\n",
    "                    print('Moving sample {0} from support to remainder set.'.format(index))\n",
    "                self.remainderSetIndices.append(index)\n",
    "                self.R = self.removeSampleFromR(minIndex)\n",
    "                self.supportSetIndices.pop(minIndex)\n",
    "            # move from support to error set\n",
    "            elif np.abs(weightsValue) == self.C:\n",
    "                if self.debug:\n",
    "                    print('Moving sample {0} from support to error set.'.format(index))\n",
    "                self.errorSetIndices.append(index)\n",
    "                self.R = self.removeSampleFromR(minIndex)\n",
    "                self.supportSetIndices.pop(minIndex)\n",
    "            else:\n",
    "                if self.debug:\n",
    "                    print('Issue with set swapping, flag 2.','weightsValue:',weightsValue)\n",
    "                sys.exit()\n",
    "        # move sample from Error set to Support set\n",
    "        elif flag == 3: \n",
    "            index = self.errorSetIndices[minIndex]\n",
    "            if self.debug:\n",
    "                print('Moving sample {0} from error to support set.'.format(index))\n",
    "            H[index] = np.sign(H[index])*self.eps\n",
    "            self.supportSetIndices.append(index)\n",
    "            self.errorSetIndices.pop(minIndex)\n",
    "            self.R = self.addSampleToR(index, 'ErrorSet', beta, gamma)\n",
    "        # move sample from Remainder set to Support set\n",
    "        elif flag == 4: \n",
    "            index = self.remainderSetIndices[minIndex]\n",
    "            if self.debug:\n",
    "                print('Moving sample {0} from remainder to support set.'.format(index))\n",
    "            H[index] = np.sign(H[index])*self.eps\n",
    "            self.supportSetIndices.append(index)\n",
    "            self.remainderSetIndices.pop(minIndex)\n",
    "            self.R = self.addSampleToR(index, 'RemainingSet', beta, gamma)\n",
    "        return H, False\n",
    "\n",
    "    def addSampleToR(self, sampleIndex, sampleOldSet, beta, gamma):\n",
    "        if self.debug:\n",
    "            print('Adding sample {0} to R matrix.'.format(sampleIndex))\n",
    "        X = np.array(self.X)\n",
    "        sampleX = X[sampleIndex,:]\n",
    "        sampleX.shape = (sampleX.size//self.numFeatures,self.numFeatures)\n",
    "        # Add first element\n",
    "        if self.R.shape[0] <= 1:\n",
    "            Rnew = np.ones([2,2])\n",
    "            Rnew[0,0] = -self.computeKernelOutput(sampleX,sampleX)\n",
    "            Rnew[1,1] = 0\n",
    "        # Other elements\n",
    "        else:\n",
    "            # recompute beta/gamma if from error/remaining set\n",
    "            if sampleOldSet == 'ErrorSet' or sampleOldSet == 'RemainingSet':\n",
    "                # beta, gamma = self.computeBetaGamma(sampleIndex)\n",
    "                Qii = self.computeKernelOutput(sampleX, sampleX)\n",
    "                Qsi = self.computeKernelOutput(X[self.supportSetIndices[0:-1],:], sampleX)\n",
    "                beta = -self.R @ np.append(np.matrix([1]),Qsi,axis=0)\n",
    "                beta[np.isnan(beta)] = 0\n",
    "                beta.shape = (len(beta),1)\n",
    "                gamma[sampleIndex] = Qii + np.append(1,Qsi.T)@beta\n",
    "                gamma[np.isnan(gamma)] = 0\n",
    "                gamma.shape = (len(gamma),1)\n",
    "            # add a column and row of zeros onto right/bottom of R\n",
    "            r,c = self.R.shape\n",
    "            Rnew = np.append(self.R, np.zeros([r,1]), axis=1)\n",
    "            Rnew = np.append(Rnew, np.zeros([1,c+1]), axis=0)\n",
    "            # update R\n",
    "            if gamma[sampleIndex] != 0:\n",
    "                # Numpy so wonky! SO WONKY.\n",
    "                beta1 = np.append(beta, [[1]], axis=0)\n",
    "                Rnew = Rnew + 1/gamma[sampleIndex].item()*beta1@beta1.T\n",
    "            if np.any(np.isnan(Rnew)):\n",
    "                if self.debug:\n",
    "                    print('R has become inconsistent. Training failed at sampleIndex {0}'.format(sampleIndex))\n",
    "                sys.exit()\n",
    "        return Rnew\n",
    "\n",
    "    def removeSampleFromR(self, sampleIndex):\n",
    "        if self.debug:\n",
    "            print('Removing sample {0} from R matrix.'.format(sampleIndex))\n",
    "        sampleIndex += 1\n",
    "        I = list(range(sampleIndex))\n",
    "        I.extend(range(sampleIndex+1,self.R.shape[0]))\n",
    "        I = np.array(I)\n",
    "        I.shape = (1,I.size)\n",
    "        if self.debug:\n",
    "            print('I',I)\n",
    "            print('RII',self.R[I.T,I])\n",
    "        # Adjust R\n",
    "        if self.R[sampleIndex,sampleIndex] != 0:\n",
    "            Rnew = self.R[I.T,I] - (self.R[I.T,sampleIndex]*self.R[sampleIndex,I]) / self.R[sampleIndex,sampleIndex].item()\n",
    "        else:\n",
    "            Rnew = np.copy(self.R[I.T,I])\n",
    "        # Check for bad things\n",
    "        if np.any(np.isnan(Rnew)):\n",
    "            if self.debug:\n",
    "                print('R has become inconsistent. Training failed removing sampleIndex {0}'.format(sampleIndex))\n",
    "            sys.exit()\n",
    "        if Rnew.size == 1:\n",
    "            if self.debug:\n",
    "                print('Time to annhilate R? R:',Rnew)\n",
    "            Rnew = np.matrix([])\n",
    "        return Rnew\n",
    "\n",
    "    def learn(self, newSampleX, newSampleY):\n",
    "        self.numSamplesTrained += 1\n",
    "        self.X.append(newSampleX)\n",
    "        self.Y.append(newSampleY)\n",
    "        self.weights = np.append(self.weights,0)\n",
    "        i = self.numSamplesTrained - 1 # stupid off-by-one errors\n",
    "        H = self.computeMargin(self.X, self.Y)\n",
    "\n",
    "        # correctly classified sample, skip the rest of the algorithm!\n",
    "        if (abs(H[i]) <= self.eps):\n",
    "            if self.debug:\n",
    "                print('Adding new sample {0} to remainder set, within eps.'.format(i))\n",
    "            if self.debug:\n",
    "                print('weights',self.weights)\n",
    "            self.remainderSetIndices.append(i)\n",
    "            return\n",
    "\n",
    "        newSampleAdded = False\n",
    "        iterations = 0\n",
    "        while not newSampleAdded:\n",
    "            # Ensure we're not looping infinitely\n",
    "            iterations += 1\n",
    "            if iterations > self.numSamplesTrained*100:\n",
    "                if self.debug:\n",
    "                    print('Warning: we appear to be in an infinite loop.')\n",
    "                sys.exit()\n",
    "                iterations = 0\n",
    "            # Compute beta/gamma for constraint optimization\n",
    "            beta, gamma = self.computeBetaGamma(i)\n",
    "            # Find minimum variation and determine how we should shift samples between sets\n",
    "            deltaC, flag, minIndex = self.findMinVariation(H, beta, gamma, i)\n",
    "            # Update weights and bias based on variation\n",
    "            if len(self.supportSetIndices) > 0 and len(beta)>0:\n",
    "                self.weights[i] += deltaC\n",
    "                delta = beta*deltaC\n",
    "                self.bias += delta.item(0)\n",
    "                # numpy is wonky...\n",
    "                weightDelta = np.array(delta[1:])\n",
    "                weightDelta.shape = (len(weightDelta),)\n",
    "                self.weights[self.supportSetIndices] += weightDelta\n",
    "                H += gamma*deltaC\n",
    "            else:\n",
    "                self.bias += deltaC\n",
    "                H += deltaC\n",
    "            # Adjust sets, moving samples between them according to flag\n",
    "            H,newSampleAdded = self.adjustSets(H, beta, gamma, i, flag, minIndex)\n",
    "        if self.debug:\n",
    "            print('weights',self.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holt-Winters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    stream detector: holt winters\n",
    "    @param m period\n",
    "'''\n",
    "def holt_winters(series, m=1440, alpha=0.2, beta=0.2, gamma=0.2):\n",
    "    def update_array(array, update):\n",
    "        updated = np.roll(array, -1)\n",
    "        updated[-1] = update\n",
    "        return updated\n",
    "            # hyper parameters\n",
    "    n = series.size\n",
    "            # sample length\n",
    "    l_lag = 0 # $l_{t-1}$\n",
    "    b_lag = 0 # $b_{t-1}$\n",
    "    s_lag = np.zeros(shape=(m))\n",
    "            # $s_{t-1}$\n",
    "    y_prd = np.zeros(shape=(n))\n",
    "            # predictions\n",
    "    for i in range(0, n):\n",
    "        y_t = series[i]\n",
    "            # observation\n",
    "        y_hat = l_lag + b_lag + s_lag[0]\n",
    "            # equation 1\n",
    "        l_t = alpha * (y_t - s_lag[0]) + (1-alpha) * (l_lag + b_lag)\n",
    "            # equation 2\n",
    "        b_t = beta * (l_t - l_lag) + (1-beta) * b_lag\n",
    "            # equation 3\n",
    "        s_t = gamma * (y_t - l_lag - b_lag) + (1-gamma) * s_lag[0]\n",
    "            # equation 4\n",
    "        l_lag = l_t\n",
    "        b_lag = b_t\n",
    "        update_array(s_lag, s_t)\n",
    "        y_prd[i] = y_hat\n",
    "    return y_prd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EWMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    stream detector: EWMA\n",
    "    @param alpha hyper parameter\n",
    "'''\n",
    "def ewma(series, alpha=0.2):\n",
    "    n = series.size\n",
    "            # sample length\n",
    "    y_lag = 0 # $y_{t-1}$\n",
    "    y_prd = np.zeros(shape=(n))\n",
    "            # predictions\n",
    "    for i in range(0, n):\n",
    "        y_t = series[i]\n",
    "            # observation\n",
    "        y_hat = alpha * y_t + (1-alpha) * y_lag\n",
    "            # equation 1\n",
    "        y_lag = y_hat\n",
    "        y_prd[i] = y_hat\n",
    "    return y_prd"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "13f244bc7c79d3f70ce79b114c81c7859949da3dd8322c40885710ecc8043591"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
